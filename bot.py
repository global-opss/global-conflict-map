import requests
import xml.etree.ElementTree as ET
import json
import time
import re
from geopy.geocoders import Nominatim

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
geolocator = Nominatim(user_agent="conflict_monitor_v6")

FEEDS = [
    "https://rss.nytimes.com/services/xml/rss/nyt/World.xml",
    "https://feeds.bbci.co.uk/news/world/rss.xml",
    "https://www.aljazeera.com/xml/rss/all.xml"
]

# –ö–µ—à –∑–∞ –ª–æ–∫–∞—Ü–∏–∏ –∑–∞ –ø–µ—Å—Ç–µ–Ω–µ –Ω–∞ API –∑–∞—è–≤–∫–∏
LOCATION_CACHE = {
    "tehran": [35.6892, 51.3890],
    "kyiv": [50.4501, 30.5234],
    "tel aviv": [32.0853, 34.7818],
    "beirut": [33.8938, 35.5018]
}

def clean_html(raw_html):
    """–ü—Ä–µ–º–∞—Ö–≤–∞ HTML —Ç–∞–≥–æ–≤–µ –∏ –∏–∑–ª–∏—à–Ω–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∏."""
    if not raw_html: return ""
    cleanr = re.compile('<.*?>')
    cleantext = re.sub(cleanr, '', raw_html)
    return cleantext.strip()

def extract_info(text, locations):
    """
    –†–∞–∑—à–∏—Ä–µ–Ω–∞ –ª–æ–≥–∏–∫–∞ –∑–∞ –∑–∞—Å–∏—á–∞–Ω–µ –Ω–∞ —Ç–∏–ø —Å—ä–±–∏—Ç–∏–µ –∏ –ª–æ–∫–∞—Ü–∏—è.
    –î–û–ë–ê–í–ï–ù–û: Critical Evacuation Check.
    """
    t = text.lower()
    
    # 1. –î–ï–§–ò–ù–ò–†–ê–ù–ï –ù–ê –°–™–ë–ò–¢–ò–Ø (–†–∞–∑—à–∏—Ä–µ–Ω —Å–ø–∏—Å—ä–∫ –∑–∞ –æ–±–µ–º –∏ —Ç–æ—á–Ω–æ—Å—Ç)
    event_map = {
        "Evacuation": ["evacuate", "leave iran", "citizens must leave", "evacuation", "emergency departure"],
        "Naval": ["ship", "vessel", "navy", "maritime", "carrier", "destroyer", "black sea fleet", "frigate"],
        "Airstrike": ["airstrike", "missile", "rocket", "bombing", "strikes", "attack", "ballistic", "explosion"],
        "Explosion": ["explosion", "blast", "shelling", "artillery", "fire", "killed", "detonation"],
        "Drone": ["drone", "uav", "shahed", "fpv", "kamikaze", "bayraktar"],
        "Clashes": ["clashes", "fighting", "battle", "siege", "frontline", "tank", "infantry"],
        "Nuclear": ["nuclear", "atomic", "radiation", "npp", "icbm", "uranium", "reactor"]
    }

    found_city, found_region = None, "World"
    
    # 2. –¢–™–†–°–ï–ù–ï –ù–ê –õ–û–ö–ê–¶–ò–Ø
    for region, cities in locations.items():
        for city in cities:
            if city.lower() in t:
                found_city, found_region = city.capitalize(), region
                break
        if found_city: break

    # 3. –û–ü–†–ï–î–ï–õ–Ø–ù–ï –ù–ê –¢–ò–ü –°–™–ë–ò–¢–ò–ï
    found_type = "Breaking News"
    for event, keywords in event_map.items():
        if any(k in t for k in keywords):
            found_type = event
            break
            
    return found_city, found_region, found_type

def get_coordinates(city, region):
    """–ò–∑–≤–ª–∏—á–∞–Ω–µ –Ω–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ —Å Nominatim –∏ –∫–µ—à–∏—Ä–∞–Ω–µ."""
    city_low = city.lower()
    if city_low in LOCATION_CACHE:
        return LOCATION_CACHE[city_low][0], LOCATION_CACHE[city_low][1]
    
    try:
        print(f"üåê Geocoding: {city}...")
        time.sleep(1.2) # –ü–∞—É–∑–∞ —Å—ä–≥–ª–∞—Å–Ω–æ –ø—Ä–∞–≤–∏–ª–∞—Ç–∞ –Ω–∞ Nominatim
        loc = geolocator.geocode(f"{city}, {region}", timeout=10)
        if loc:
            LOCATION_CACHE[city_low] = [loc.latitude, loc.longitude]
            return loc.latitude, loc.longitude
    except Exception as e:
        print(f"‚ùå Geocode Error: {e}")
        return None, None
    return None, None

def run_bot():
    """–û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥–∏–∫–∞ –Ω–∞ –±–æ—Ç–∞ - –°–¢–†–ò–ö–¢–ù–û 151+ –†–ï–î–ê."""
    all_events = []
    
    # –°–ø–∏—Å—ä–∫ —Å –≥—Ä–∞–¥–æ–≤–µ –∑–∞ —Ç—ä—Ä—Å–µ–Ω–µ (–ü—Ä–∏–º–µ—Ä–µ–Ω - —Ä–∞–∑—à–∏—Ä–∏ –≥–æ –≤ —Ç–≤–æ—è –ø—Ä–æ–µ–∫—Ç)
    locations = {
        "Iran": ["Tehran", "Isfahan", "Bushehr", "Tabriz", "Mashhad"],
        "Ukraine": ["Kyiv", "Kharkiv", "Odesa", "Lviv", "Donetsk"],
        "Russia": ["Moscow", "Sevastopol", "Belgorod", "Engels"],
        "Israel": ["Tel Aviv", "Jerusalem", "Haifa", "Gaza"]
    }

    print(f"üì° --- STARTING INTEL SCAN v7 (CRITICAL EVACUATION UPDATE) ---")
    
    for url in FEEDS:
        domain = url.split('/')[2]
        print(f"üîç Accessing Source: {domain}...")
        
        try:
            headers = {'User-Agent': USER_AGENT}
            res = requests.get(url, headers=headers, timeout=10)
            
            if res.status_code != 200:
                print(f"‚ö†Ô∏è Source Offline ({res.status_code}): {domain}")
                continue
            
            # –ü–∞—Ä—Å–≤–∞–Ω–µ –Ω–∞ RSS —Å—Ç—Ä—É–∫—Ç—É—Ä–∞—Ç–∞
            root = ET.fromstring(res.content)
            items = root.findall('.//item')
            print(f"üóûÔ∏è Found {len(items)} potential headlines in {domain}")

            for item in items[:15]: # –ê–Ω–∞–ª–∏–∑ –Ω–∞ —Ç–æ–ø 15 –Ω–æ–≤–∏–Ω–∏
                raw_title = item.find('title').text if item.find('title') is not None else ""
                raw_desc = item.find('description').text if item.find('description') is not None else ""
                link = item.find('link').text if item.find('link') is not None else "#"

                title = clean_html(raw_title)
                desc = clean_html(raw_desc)

                # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –¥—ä–ª–∂–∏–Ω–∞—Ç–∞
                if len(title) < 20: continue
                
                # –ò–ó–í–õ–ò–ß–ê–ù–ï –ù–ê –ò–ù–§–û–†–ú–ê–¶–ò–Ø
                city, region, event_type = extract_info(title + " " + desc, locations)
                
                if city:
                    lat, lon = get_coordinates(city, region)
                    
                    if lat and lon:
                        # –õ–æ–≥–∏–∫–∞ –∑–∞ —Å–º—ä—Ä—Ç–Ω–∏ —Å–ª—É—á–∞–∏
                        death_match = re.search(r'(\d+)\s+(killed|dead|fatalities|casualties)', (title + " " + desc).lower())
                        fatalities = death_match.group(1) if death_match else "0"
                        
                        # –î–æ–±–∞–≤—è–Ω–µ –∫—ä–º —Å–ø–∏—Å—ä–∫–∞
                        event_data = {
                            "country": region,
                            "city": city,
                            "lat": lat,
                            "lon": lon,
                            "date": time.strftime("%Y-%m-%d %H:%M:%S"),
                            "type": event_type, 
                            "title": title[:120],
                            "description": desc[:400] if desc else f"Strategic update from {city} sector.",
                            "fatalities": fatalities,
                            "link": link,
                            "critical": True if event_type == "Evacuation" else False
                        }
                        
                        all_events.append(event_data)
                        print(f"‚úÖ Event Captured: [{event_type}] in {city}")

        except Exception as e:
            print(f"üí• Critical Error on {url}: {str(e)}")

    # –ü–†–ï–ú–ê–•–í–ê–ù–ï –ù–ê –î–£–ë–õ–ò–ö–ê–¢–ò (–±–∞–∑–∏—Ä–∞–Ω–æ –Ω–∞ –∑–∞–≥–ª–∞–≤–∏–µ)
    print(f"üßπ Filtering duplicates...")
    unique_events = {}
    for event in all_events:
        unique_events[event['title']] = event
    
    final_list = list(unique_events.values())

    # –ó–ê–ü–ò–° –í JSON –§–ê–ô–õ
    try:
        print(f"üíæ Saving data to conflicts.json...")
        with open('conflicts.json', 'w', encoding='utf-8') as f:
            json.dump(final_list, f, indent=4, ensure_ascii=False)
        print(f"üöÄ DEPLOYMENT READY. TOTAL EVENTS: {len(final_list)}")
    except IOError as io_err:
        print(f"üìÅ File Error: Could not write JSON: {io_err}")

# --- –¢–û–ß–ö–ê –ù–ê –°–¢–ê–†–¢–ò–†–ê–ù–ï ---
if __name__ == "__main__":
    start_time = time.time()
    run_bot()
    end_time = time.time()
    print(f"‚è±Ô∏è Process completed in {round(end_time - start_time, 2)} seconds.")
    # –ö—Ä–∞–π –Ω–∞ —Å–∫—Ä–∏–ø—Ç–∞ - GitHub Actions —â–µ –∑–∞—Ç–≤–æ—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ.
